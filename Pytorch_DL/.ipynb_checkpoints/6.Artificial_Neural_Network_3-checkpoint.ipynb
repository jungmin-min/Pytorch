{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223bbadb",
   "metadata": {},
   "source": [
    "## 6-7. 다층 퍼셉트론으로 손글씨 분류하기\n",
    "### 1. 숫자 필기 데이터 소개\n",
    "숫자 필기 데이터는 사이킷런 패키지에서 제공하는 분류용 예제 데이터임. 0 ~ 9까지 손으로 쓴 이미지 데이터. load_digits() 명령으로 로드할 수 있다. 각 이미지는 0 ~ 15까지의 명암을 가지는 8x8=64 픽셀 해상도의 흑백 이미지임. 해당 이미지가 1,797개 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a54ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt #시각화를 위한 맷플롯립\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7696f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3c960",
   "metadata": {},
   "source": [
    "0을 흰색 도화지, 0보다 큰 숫자들을 검은색 점이라고 상상해보면 숫자 0의 실루엣처럼 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c620b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (digits.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b0b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 1797\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수: {}'.format(len(digits.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e8c33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전체 샘플 1797개 중 상위 5개의 샘플만 시각화\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:5]): #5개의 샘플만 출력\n",
    "    plt.subplot(2, 5, index +1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('sample: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9429c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번 인덱스 샘플의 레이블:  0\n",
      "1 번 인덱스 샘플의 레이블:  1\n",
      "2 번 인덱스 샘플의 레이블:  2\n",
      "3 번 인덱스 샘플의 레이블:  3\n",
      "4 번 인덱스 샘플의 레이블:  4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, '번 인덱스 샘플의 레이블: ', digits.target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d11cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 레이블을 각각 X, Y에 저장\n",
    "# digits.data 함수는 8x8행렬을 64차원의 벡터로 변환한 형태임.\n",
    "print(digits.data[0])\n",
    "X = digits.data   #이미지. 즉, 특성 행렬\n",
    "Y = digits.target #각 이미지에 대한 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452697f5",
   "metadata": {},
   "source": [
    "### 2. 다층 퍼셉트론 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8cab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166de36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 32), #input_layer = 64, hidden_layer1 = 32\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16), #hidden_layer1 = 32, hidden_layer2 = 16\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10)  #hidden_layer2 = 16, output_layer = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f3c89e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024519f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() #이 비용함수는 소프트맥스 함수를 포함하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379cb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21298ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72157aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 2.644159\n",
      "Epoch   10/100 Cost: 2.185431\n",
      "Epoch   20/100 Cost: 1.983278\n",
      "Epoch   30/100 Cost: 1.720703\n",
      "Epoch   40/100 Cost: 1.451564\n",
      "Epoch   50/100 Cost: 1.176492\n",
      "Epoch   60/100 Cost: 0.900471\n",
      "Epoch   70/100 Cost: 0.651608\n",
      "Epoch   80/100 Cost: 0.459725\n",
      "Epoch   90/100 Cost: 0.338111\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X) # forward연산\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, 100, loss.item()))\n",
    "              \n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7fce7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4a3a0e350>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6b285",
   "metadata": {},
   "source": [
    "## 6-8. 다층 퍼셉트론으로 MNIST 분류하기\n",
    "5장 소프트맥스 회귀에서 입력층과 출력층만 존재하는 단층 퍼셉트론에서 소프트맥스 함수를 활성화 함수로 사용하였음. <br>\n",
    "이번 챕터에서는 은닉층을 추가로 넣어 다층 퍼셉트론 구현\n",
    "### 1. 데이터 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87cc9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2e050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54f82d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n",
       "        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n",
       "       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n",
       "       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n",
       "       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n",
       "       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n",
       "       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n",
       "       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n",
       "       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n",
       "       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0] # KeyError: 0 as_frame=False추가 오류 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f88aa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "862d294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.target = mnist.target.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50df14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data / 255 #0~255값을 [0,1]구간으로 정규화\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95ced7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cd82e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0d39e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지 데이터의 레이블은 5이다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
    "print('이 이미지 데이터의 레이블은 {:.0f}이다.'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081c6b0",
   "metadata": {},
   "source": [
    "### 2. 훈련 데이터와 테스트 데이터의 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba5a3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79d84ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=1/7, random_state=0)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4776b60",
   "metadata": {},
   "source": [
    "### 3. 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "018163b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(100, 100))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(100, 10))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3bfa124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#오차함수 선택\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#가중치를 학습하기 위한 최적화 기법 선택\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87247e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train() #신경망을 학습 모드로 전환\n",
    "    \n",
    "    #데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad() #경사를 0으로 초기화\n",
    "        outputs = model(data) #데이터를 입력하고 출력을 계산\n",
    "        loss = loss_fn(outputs, targets) #출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "        loss.backward()  #오차를 역전파 계산\n",
    "        optimizer.step() #역전파 계산한 값으로 가중치를 수정\n",
    "        \n",
    "    print(\"epoch{}: 완료\\n\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9a67bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval() #신경망을 추론 모드로 전환\n",
    "    correct = 0\n",
    "    \n",
    "    #데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "    with torch.no_grad(): #추론 과정에는 미분이 필요 없음\n",
    "        for data, targets in loader_test:\n",
    "            outputs = model(data) #데이터를 입력하고 출력을 계산\n",
    "            \n",
    "            #추론 계산\n",
    "            _, predicted = torch.max(outputs.data, 1) #확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum() #정답과 일치한 경우 정답 카운트를 증가\n",
    "            \n",
    "            #정확도 출력\n",
    "            data_num = len(loader_test.dataset) #데이터 총 건수\n",
    "            print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100.*correct/data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4239b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 데이터에서 예측 정확도: 2/10000 (0%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9/10000 (0%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 17/10000 (0%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 30/10000 (0%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 40/10000 (0%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 53/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 65/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 71/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 73/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 83/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 94/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 107/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 116/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 121/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 133/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 139/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 150/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 160/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 167/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 169/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 177/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 181/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 187/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 194/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 202/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 210/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 214/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 219/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 227/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 233/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 240/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 249/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 252/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 258/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 266/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 273/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 280/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 286/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 288/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 295/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 306/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 312/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 319/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 328/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 333/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 344/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 348/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 356/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 366/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 371/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 378/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 383/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 387/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 397/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 405/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 411/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 417/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 424/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 432/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 440/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 449/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 454/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 456/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 461/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 466/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 474/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 482/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 492/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 497/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 500/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 508/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 511/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 513/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 521/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 532/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 542/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 551/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 560/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 568/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 576/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 582/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 589/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 596/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 601/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 613/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 621/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 631/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 639/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 641/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 649/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 654/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 666/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 675/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 683/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 688/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 690/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 694/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 702/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 712/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 719/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 724/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 728/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 732/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 738/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 746/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 756/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 762/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 774/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 781/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 789/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 799/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 804/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 812/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 818/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 825/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 832/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 835/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 839/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 848/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 852/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 855/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 861/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 867/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 870/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 885/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 893/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 899/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 908/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 913/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 921/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 927/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 931/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 933/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 941/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 947/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 956/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 959/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 965/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 970/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 978/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 985/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 992/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1001/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1010/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1016/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1021/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1029/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1033/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1038/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1046/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1055/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1061/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1070/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1076/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1088/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1095/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1096/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de14b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: 완료\n",
      "\n",
      "epoch1: 완료\n",
      "\n",
      "epoch2: 완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 63/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 125/10000 (1%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 187/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 248/10000 (2%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 309/10000 (3%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 371/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 429/10000 (4%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 493/10000 (5%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 552/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 615/10000 (6%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 668/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 728/10000 (7%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 789/10000 (8%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 851/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 911/10000 (9%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 971/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1033/10000 (10%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1096/10000 (11%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1158/10000 (12%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1222/10000 (12%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1285/10000 (13%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1343/10000 (13%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1406/10000 (14%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1467/10000 (15%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1525/10000 (15%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1588/10000 (16%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1650/10000 (16%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1713/10000 (17%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1775/10000 (18%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1837/10000 (18%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1900/10000 (19%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 1962/10000 (20%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2026/10000 (20%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2088/10000 (21%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2150/10000 (22%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2210/10000 (22%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2271/10000 (23%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2333/10000 (23%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2395/10000 (24%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2457/10000 (25%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2516/10000 (25%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2576/10000 (26%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2636/10000 (26%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2696/10000 (27%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2755/10000 (28%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2814/10000 (28%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2877/10000 (29%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2938/10000 (29%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 2999/10000 (30%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3061/10000 (31%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3125/10000 (31%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3182/10000 (32%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3242/10000 (32%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3305/10000 (33%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3367/10000 (34%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3425/10000 (34%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3487/10000 (35%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3549/10000 (35%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3610/10000 (36%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3672/10000 (37%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3732/10000 (37%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3792/10000 (38%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3852/10000 (39%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3914/10000 (39%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 3978/10000 (40%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4042/10000 (40%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4102/10000 (41%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4163/10000 (42%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4224/10000 (42%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4284/10000 (43%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4345/10000 (43%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4408/10000 (44%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4469/10000 (45%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4531/10000 (45%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4593/10000 (46%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4652/10000 (47%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4713/10000 (47%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4776/10000 (48%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4836/10000 (48%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4896/10000 (49%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4958/10000 (50%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5019/10000 (50%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5079/10000 (51%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5141/10000 (51%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5205/10000 (52%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5267/10000 (53%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5324/10000 (53%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5386/10000 (54%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5448/10000 (54%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5512/10000 (55%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5571/10000 (56%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5630/10000 (56%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5693/10000 (57%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5756/10000 (58%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5815/10000 (58%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5874/10000 (59%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5936/10000 (59%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5994/10000 (60%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6055/10000 (61%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6115/10000 (61%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6176/10000 (62%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6238/10000 (62%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6302/10000 (63%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6365/10000 (64%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6426/10000 (64%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6486/10000 (65%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6549/10000 (65%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6611/10000 (66%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6671/10000 (67%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6732/10000 (67%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6792/10000 (68%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6854/10000 (69%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6916/10000 (69%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 6978/10000 (70%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7035/10000 (70%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7096/10000 (71%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7160/10000 (72%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7221/10000 (72%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7281/10000 (73%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7339/10000 (73%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7402/10000 (74%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7462/10000 (75%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7522/10000 (75%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7581/10000 (76%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7637/10000 (76%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7696/10000 (77%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7758/10000 (78%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7818/10000 (78%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7879/10000 (79%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7942/10000 (79%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8005/10000 (80%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8067/10000 (81%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8128/10000 (81%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8190/10000 (82%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8250/10000 (82%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8310/10000 (83%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8370/10000 (84%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8431/10000 (84%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8493/10000 (85%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8554/10000 (86%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8612/10000 (86%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8675/10000 (87%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8738/10000 (87%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8798/10000 (88%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8857/10000 (89%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8918/10000 (89%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 8977/10000 (90%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9039/10000 (90%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9100/10000 (91%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9161/10000 (92%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9219/10000 (92%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9280/10000 (93%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9338/10000 (93%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9399/10000 (94%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9461/10000 (95%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9519/10000 (95%)\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9534/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): #세번의 train 후 test 결과 확인\n",
    "    train(epoch)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f2e9426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: 2\n",
      "이 이미지 데이터의 정답 레이블은 2입니다\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 2018\n",
    "\n",
    "model.eval() #신경망을 추론 모드로 전환\n",
    "data = X_test[index]\n",
    "output = model(data) #데이터를 입력하고 출력을 계산\n",
    "_, predicted = torch.max(output.data, 0) #확률이 가장 높은 레이블이 무엇인지 계산\n",
    "\n",
    "\n",
    "print(\"예측 결과: {}\".format(predicted))\n",
    "\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28, 28), cmap='gray')\n",
    "print('이 이미지 데이터의 정답 레이블은 {:.0f}입니다'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657e053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
